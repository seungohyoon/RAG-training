{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 환경설정\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기본 라이브러리\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a604c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선언\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0.1,\n",
    "    top_p=0.9, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9001864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## csv 문서 로드\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# 기본 파일 로드\n",
    "csv_loader = CSVLoader(\"./data/skrc_faq.csv\", encoding=\"utf-8\")\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(csv_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", csv_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", csv_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699890cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CSV 문서 메타데이터 변환 및 키워드/요약 추출\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 키워드와 요약을 추출하는 함수\n",
    "def extract_keyword_and_summary(text, llm):\n",
    "    \"\"\"텍스트에서 키워드와 요약을 추출하는 함수\"\"\"\n",
    "    \n",
    "    # 키워드 추출 프롬프트\n",
    "    keyword_prompt = f\"\"\"\n",
    "    다음 텍스트에서 핵심 키워드 3-5개를 추출해주세요. \n",
    "    쉼표로 구분하여 답변하세요.\n",
    "    \n",
    "    텍스트: {text}\n",
    "    \n",
    "    키워드:\"\"\"\n",
    "    \n",
    "    # 요약 추출 프롬프트\n",
    "    summary_prompt = f\"\"\"\n",
    "    다음 텍스트를 2-3문장으로 요약해주세요.\n",
    "    \n",
    "    텍스트: {text}\n",
    "    \n",
    "    요약:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # 키워드 추출\n",
    "        keyword_response = llm.invoke(keyword_prompt)\n",
    "        keywords = keyword_response.content.strip()\n",
    "        \n",
    "        # 요약 추출\n",
    "        summary_response = llm.invoke(summary_prompt)\n",
    "        summary = summary_response.content.strip()\n",
    "        \n",
    "        return keywords, summary\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"키워드/요약 추출 실패: {e}\")\n",
    "        return \"키워드 추출 실패\", \"요약 추출 실패\"\n",
    "\n",
    "# CSV 문서를 새로운 메타데이터 형식으로 변환\n",
    "def transform_csv_docs_metadata(csv_docs, llm):\n",
    "    \"\"\"CSV 문서의 메타데이터를 새로운 형식으로 변환\"\"\"\n",
    "    \n",
    "    transformed_docs = []\n",
    "    \n",
    "    for i, doc in enumerate(csv_docs):\n",
    "        try:\n",
    "            # 기존 내용에서 질문과 답변 추출\n",
    "            content = doc.page_content\n",
    "            \n",
    "            # CSV 형식에 따라 질문과 답변 파싱\n",
    "            if 'question:' in content and 'answer:' in content:\n",
    "                # 질문과 답변 분리\n",
    "                parts = content.split('answer:')\n",
    "                question_part = parts[0].replace('question:', '').strip()\n",
    "                answer_part = parts[1].strip()\n",
    "                \n",
    "                question = question_part\n",
    "                answer = answer_part\n",
    "            else:\n",
    "                # 다른 형식인 경우 전체 내용을 사용\n",
    "                question = content\n",
    "                answer = content\n",
    "            \n",
    "            # 키워드와 요약 추출\n",
    "            full_text = f\"{question}\\n\\n{answer}\"\n",
    "            keywords, summary = extract_keyword_and_summary(full_text, llm)\n",
    "            \n",
    "            # 새로운 Document 객체 생성\n",
    "            new_doc = Document(\n",
    "                page_content=doc.page_content,  # 기존 내용 유지\n",
    "                metadata={\n",
    "                    'question_id': i + 1,  # 1부터 시작하는 ID\n",
    "                    'question': question,\n",
    "                    'answer': answer,\n",
    "                    'keyword': keywords,\n",
    "                    'summary': summary\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            transformed_docs.append(new_doc)\n",
    "            \n",
    "            # 진행상황 출력\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"처리 진행률: {i + 1}/{len(csv_docs)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"문서 {i+1} 변환 실패: {e}\")\n",
    "            # 실패한 경우 기본값으로 생성\n",
    "            new_doc = Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\n",
    "                    'question_id': i + 1,\n",
    "                    'question': '질문 추출 실패',\n",
    "                    'answer': '답변 추출 실패',\n",
    "                    'keyword': '키워드 추출 실패',\n",
    "                    'summary': '요약 추출 실패'\n",
    "                }\n",
    "            )\n",
    "            transformed_docs.append(new_doc)\n",
    "    \n",
    "    return transformed_docs\n",
    "\n",
    "# 메타데이터 변환 실행\n",
    "print(\"CSV 문서 메타데이터 변환 시작...\")\n",
    "transformed_docs = transform_csv_docs_metadata(csv_docs, llm)\n",
    "\n",
    "print(f\"\\n✅ 변환 완료! 총 {len(transformed_docs)}개 문서\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899df378",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 벡터DB에 transformed_docs 저장\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "# 임베딩 모델 설정\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 벡터DB 저장 경로\n",
    "vector_db_path = \"./vector_db/skrc_faq\"\n",
    "\n",
    "# 기존 벡터DB 삭제\n",
    "if os.path.exists(vector_db_path):\n",
    "    import shutil\n",
    "    shutil.rmtree(vector_db_path)\n",
    "\n",
    "# 벡터DB 생성 및 저장\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=transformed_docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=vector_db_path\n",
    ")\n",
    "\n",
    "vectorstore.persist()\n",
    "print(f\"✅ 벡터DB 저장 완료: {len(transformed_docs)}개 문서\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf0ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensemble Retriever를 이용한 검색\n",
    "\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 임베딩 모델과 벡터DB 로드\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_db_path = \"./vector_db/skrc_faq\"\n",
    "\n",
    "# 벡터 검색기 (Vector Retriever)\n",
    "vector_retriever = Chroma(\n",
    "    persist_directory=vector_db_path,\n",
    "    embedding_function=embeddings\n",
    ").as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# BM25 검색기 (키워드 기반 검색)\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=transformed_docs\n",
    ")\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# Ensemble Retriever 생성\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    weights=[0.7, 0.3]  # 벡터 검색에 더 높은 가중치\n",
    ")\n",
    "\n",
    "print(\"✅ Ensemble Retriever 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2478ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAG chain 구성\n",
    "\n",
    "## RAG Chain - Ensemble Retriever를 이용한 답변 생성\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# RAG를 위한 프롬프트 템플릿 생성\n",
    "qa_prompt_template = \"\"\"당신은 SK렌터카의 친절한 고객 상담원입니다. \n",
    "아래의 참조 문서를 바탕으로 고객의 질문에 정확하고 친절하게 답변해주세요.\n",
    "\n",
    "참조 문서:\n",
    "{context}\n",
    "\n",
    "고객 질문: {question}\n",
    "\n",
    "답변 시 다음 사항을 지켜주세요:\n",
    "1. 참조 문서의 내용을 바탕으로 정확한 정보 제공\n",
    "2. 친근하고 이해하기 쉬운 언어 사용\n",
    "3. 필요한 경우 구체적인 예시나 단계별 설명 제공\n",
    "4. 한국어로 답변\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "QA_PROMPT = PromptTemplate(\n",
    "    template=qa_prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# RAG Chain 생성\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=ensemble_retriever,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": QA_PROMPT,\n",
    "        \"verbose\": True\n",
    "    },\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"✅ RAG Chain 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19385e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradio를 이용한 대화형 SK렌터카 FAQ 챗봇 (에러 수정)\n",
    "\n",
    "import gradio as gr\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 기존 설정들 로드\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_db_path = \"./vector_db/skrc_faq\"\n",
    "\n",
    "# 벡터 검색기\n",
    "vector_retriever = Chroma(\n",
    "    persist_directory=vector_db_path,\n",
    "    embedding_function=embeddings\n",
    ").as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# BM25 검색기\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=transformed_docs\n",
    ")\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# Ensemble Retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    weights=[0.7, 0.3]\n",
    ")\n",
    "\n",
    "# LLM 모델\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0.1,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "def get_faq_answer(question):\n",
    "    \"\"\"FAQ 질문에 대한 답변을 생성하는 함수\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Ensemble Retriever로 관련 문서 검색\n",
    "        relevant_docs = ensemble_retriever.get_relevant_documents(question, k=3)\n",
    "        \n",
    "        # 컨텍스트 생성\n",
    "        context = \"\"\n",
    "        for i, doc in enumerate(relevant_docs):\n",
    "            context += f\"[문서 {i+1}]\\n\"\n",
    "            context += f\"질문: {doc.metadata['question']}\\n\"\n",
    "            context += f\"답변: {doc.metadata['answer']}\\n\"\n",
    "            context += f\"요약: {doc.metadata['summary']}\\n\\n\"\n",
    "        \n",
    "        # 수정된 RAG 프롬프트\n",
    "        prompt = f\"\"\"당신은 SK렌터카의 친절한 고객 상담원입니다.\n",
    "\n",
    "참조 문서:\n",
    "{context}\n",
    "\n",
    "고객 질문: {question}\n",
    "\n",
    "위 참조 문서를 바탕으로 정확하고 친절하게 답변해주세요.\n",
    "\n",
    "**중요한 규칙:**\n",
    "1. 명확한 근거가 없으면 \"근거없음\"으로 답변하세요\n",
    "2. 답변하기 어려운 질문은 \"잘 모르겠습니다\"라고 대답하세요\n",
    "3. 추측이나 일반적인 지식을 이용하지 마세요\n",
    "4. 참조 문서의 내용만을 바탕으로 답변하세요\n",
    "5. 답변은 한국어로 작성하고, 필요시 구체적인 예시를 포함하세요\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "        # 답변 생성\n",
    "        response = llm.invoke(prompt)\n",
    "        answer = response.content\n",
    "        \n",
    "        # 참조 문서 정보 추가\n",
    "        reference_info = \"\\n\\n📚 참조 문서:\\n\"\n",
    "        for i, doc in enumerate(relevant_docs):\n",
    "            reference_info += f\"• {doc.metadata['question']}\\n\"\n",
    "        \n",
    "        full_answer = answer + reference_info\n",
    "        \n",
    "        return full_answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"죄송합니다. 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "# Gradio 인터페이스 구성\n",
    "with gr.Blocks(title=\"SK렌터카 FAQ 챗봇\", theme=gr.themes.Soft()) as demo:\n",
    "    \n",
    "    # 헤더\n",
    "    gr.Markdown(\"# �� SK렌터카 FAQ 챗봇\")\n",
    "    gr.Markdown(\"렌터카 이용에 궁금한 점이 있으시면 언제든 물어보세요!\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            # 챗봇 인터페이스 - 메시지 형식 수정\n",
    "            chatbot = gr.Chatbot(\n",
    "                height=500, \n",
    "                show_label=False\n",
    "            )\n",
    "            \n",
    "            # 입력 필드와 버튼을 한 줄에 배치\n",
    "            with gr.Row():\n",
    "                msg = gr.Textbox(\n",
    "                    placeholder=\"질문을 입력하세요...\",\n",
    "                    show_label=False,\n",
    "                    lines=2,\n",
    "                    scale=4\n",
    "                )\n",
    "                submit_btn = gr.Button(\"전송\", variant=\"primary\", size=\"lg\", scale=1)\n",
    "            \n",
    "            # 대화 초기화 버튼\n",
    "            clear = gr.Button(\"대화 초기화\", variant=\"secondary\")\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### 💡 예시 질문\")\n",
    "            gr.Markdown(\"\"\"\n",
    "            • 제주지점에서 이용 가능한 부가용품은 무엇인가요?\n",
    "            • 렌터카 결제는 어떻게 하나요?\n",
    "            • 유아용품을 대여할 수 있나요?\n",
    "            • 전기차 충전료는 어떻게 정산되나요?\n",
    "            • 예약을 변경하고 싶어요\n",
    "            \"\"\")\n",
    "    \n",
    "    def respond(message, chat_history):\n",
    "        if message.strip() == \"\":\n",
    "            return chat_history, \"\"\n",
    "        \n",
    "        bot_message = get_faq_answer(message)\n",
    "        \n",
    "        # 메시지 형식을 올바르게 구성\n",
    "        chat_history.append([message, bot_message])\n",
    "        return chat_history, \"\"\n",
    "    \n",
    "    # 이벤트 연결\n",
    "    submit_btn.click(respond, [msg, chatbot], [chatbot, msg])  # 전송 버튼 클릭\n",
    "    msg.submit(respond, [msg, chatbot], [chatbot, msg])        # Enter 키 입력\n",
    "    clear.click(lambda: ([], \"\"), outputs=[chatbot, msg])       # 초기화 버튼\n",
    "\n",
    "# Gradio 앱 실행\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 먼저 7860 포트로 시도\n",
    "        demo.launch(\n",
    "            server_name=\"127.0.0.1\",\n",
    "            server_port=7860,\n",
    "            share=True,\n",
    "            show_error=True\n",
    "        )\n",
    "    except OSError:\n",
    "        try:\n",
    "            # 7860이 사용 중이면 7861로 시도\n",
    "            print(\"포트 7860이 사용 중입니다. 포트 7861로 시도합니다...\")\n",
    "            demo.launch(\n",
    "                server_name=\"127.0.0.1\",\n",
    "                server_port=7861,\n",
    "                share=True,\n",
    "                show_error=True\n",
    "            )\n",
    "        except OSError:\n",
    "            # 자동으로 사용 가능한 포트 찾기\n",
    "            print(\"자동으로 사용 가능한 포트를 찾습니다...\")\n",
    "            demo.launch(\n",
    "                server_name=\"127.0.0.1\",\n",
    "                server_port=None,  # 자동 포트 할당\n",
    "                share=True,\n",
    "                show_error=True\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
