{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954d011d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 환경설정\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ee2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기본 라이브러리\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a604c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선언\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0.1,\n",
    "    top_p=0.9, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9001864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 42\n",
      "--------------------------------------------------\n",
      "처음 문서의 메타데이터: \n",
      " {'source': './data/skrc_faq.csv', 'row': 0}\n",
      "--------------------------------------------------\n",
      "처음 문서의 내용: \n",
      " question: 제주지점에서 이용 가능한 부가용품은 무엇이 있나요?\n",
      "answer: 고객님의 즐거운 여행을 위해 제주지점만의 다양한 부가용품을 운영하고 있어요.\n",
      "차량 예약 시 부가상품도 한 번에 예약하고 결제하실 수 있어요. \n",
      "\n",
      "• 유아용품 : 유모차, 카시트\n",
      "• 전기차 여행템  : 카페KIT, 시네마 KIT(국산 전기차 전용, * 니로 제외)\n",
      "• 여행템(전 차종) :  자전거, 트레킹, 피크닉 세트\n",
      "• 키즈 굿즈 :  쿨시트, 부스터, 킥보드, 햇빛 가리개\n"
     ]
    }
   ],
   "source": [
    "## csv 문서 로드\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# 기본 파일 로드\n",
    "csv_loader = CSVLoader(\"./data/skrc_faq.csv\", encoding=\"utf-8\")\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(csv_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", csv_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", csv_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "699890cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 문서 메타데이터 변환 시작...\n",
      "처리 진행률: 10/42\n",
      "처리 진행률: 20/42\n",
      "처리 진행률: 30/42\n",
      "처리 진행률: 40/42\n",
      "\n",
      "✅ 변환 완료! 총 42개 문서\n"
     ]
    }
   ],
   "source": [
    "## CSV 문서 메타데이터 변환 및 키워드/요약 추출\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 키워드와 요약을 추출하는 함수\n",
    "def extract_keyword_and_summary(text, llm):\n",
    "    \"\"\"텍스트에서 키워드와 요약을 추출하는 함수\"\"\"\n",
    "    \n",
    "    # 키워드 추출 프롬프트\n",
    "    keyword_prompt = f\"\"\"\n",
    "    다음 텍스트에서 핵심 키워드 3-5개를 추출해주세요. \n",
    "    쉼표로 구분하여 답변하세요.\n",
    "    \n",
    "    텍스트: {text}\n",
    "    \n",
    "    키워드:\"\"\"\n",
    "    \n",
    "    # 요약 추출 프롬프트\n",
    "    summary_prompt = f\"\"\"\n",
    "    다음 텍스트를 2-3문장으로 요약해주세요.\n",
    "    \n",
    "    텍스트: {text}\n",
    "    \n",
    "    요약:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # 키워드 추출\n",
    "        keyword_response = llm.invoke(keyword_prompt)\n",
    "        keywords = keyword_response.content.strip()\n",
    "        \n",
    "        # 요약 추출\n",
    "        summary_response = llm.invoke(summary_prompt)\n",
    "        summary = summary_response.content.strip()\n",
    "        \n",
    "        return keywords, summary\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"키워드/요약 추출 실패: {e}\")\n",
    "        return \"키워드 추출 실패\", \"요약 추출 실패\"\n",
    "\n",
    "# CSV 문서를 새로운 메타데이터 형식으로 변환\n",
    "def transform_csv_docs_metadata(csv_docs, llm):\n",
    "    \"\"\"CSV 문서의 메타데이터를 새로운 형식으로 변환\"\"\"\n",
    "    \n",
    "    transformed_docs = []\n",
    "    \n",
    "    for i, doc in enumerate(csv_docs):\n",
    "        try:\n",
    "            # 기존 내용에서 질문과 답변 추출\n",
    "            content = doc.page_content\n",
    "            \n",
    "            # CSV 형식에 따라 질문과 답변 파싱\n",
    "            if 'question:' in content and 'answer:' in content:\n",
    "                # 질문과 답변 분리\n",
    "                parts = content.split('answer:')\n",
    "                question_part = parts[0].replace('question:', '').strip()\n",
    "                answer_part = parts[1].strip()\n",
    "                \n",
    "                question = question_part\n",
    "                answer = answer_part\n",
    "            else:\n",
    "                # 다른 형식인 경우 전체 내용을 사용\n",
    "                question = content\n",
    "                answer = content\n",
    "            \n",
    "            # 키워드와 요약 추출\n",
    "            full_text = f\"{question}\\n\\n{answer}\"\n",
    "            keywords, summary = extract_keyword_and_summary(full_text, llm)\n",
    "            \n",
    "            # 새로운 Document 객체 생성\n",
    "            new_doc = Document(\n",
    "                page_content=doc.page_content,  # 기존 내용 유지\n",
    "                metadata={\n",
    "                    'question_id': i + 1,  # 1부터 시작하는 ID\n",
    "                    'question': question,\n",
    "                    'answer': answer,\n",
    "                    'keyword': keywords,\n",
    "                    'summary': summary\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            transformed_docs.append(new_doc)\n",
    "            \n",
    "            # 진행상황 출력\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"처리 진행률: {i + 1}/{len(csv_docs)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"문서 {i+1} 변환 실패: {e}\")\n",
    "            # 실패한 경우 기본값으로 생성\n",
    "            new_doc = Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\n",
    "                    'question_id': i + 1,\n",
    "                    'question': '질문 추출 실패',\n",
    "                    'answer': '답변 추출 실패',\n",
    "                    'keyword': '키워드 추출 실패',\n",
    "                    'summary': '요약 추출 실패'\n",
    "                }\n",
    "            )\n",
    "            transformed_docs.append(new_doc)\n",
    "    \n",
    "    return transformed_docs\n",
    "\n",
    "# 메타데이터 변환 실행\n",
    "print(\"CSV 문서 메타데이터 변환 시작...\")\n",
    "transformed_docs = transform_csv_docs_metadata(csv_docs, llm)\n",
    "\n",
    "print(f\"\\n✅ 변환 완료! 총 {len(transformed_docs)}개 문서\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899df378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 벡터DB 저장 완료: 42개 문서\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SKTelecom\\AppData\\Local\\Temp\\ipykernel_26956\\2513845666.py:25: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "## 벡터DB에 transformed_docs 저장\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "# 임베딩 모델 설정\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 벡터DB 저장 경로\n",
    "vector_db_path = \"./vector_db/skrc_faq\"\n",
    "\n",
    "# 기존 벡터DB 삭제\n",
    "if os.path.exists(vector_db_path):\n",
    "    import shutil\n",
    "    shutil.rmtree(vector_db_path)\n",
    "\n",
    "# 벡터DB 생성 및 저장\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=transformed_docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=vector_db_path\n",
    ")\n",
    "\n",
    "vectorstore.persist()\n",
    "print(f\"✅ 벡터DB 저장 완료: {len(transformed_docs)}개 문서\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf0ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ensemble Retriever 생성 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SKTelecom\\AppData\\Local\\Temp\\ipykernel_26956\\1136353814.py:14: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_retriever = Chroma(\n"
     ]
    }
   ],
   "source": [
    "## Ensemble Retriever를 이용한 검색\n",
    "\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 임베딩 모델과 벡터DB 로드\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_db_path = \"./vector_db/skrc_faq\"\n",
    "\n",
    "# 벡터 검색기 (Vector Retriever)\n",
    "vector_retriever = Chroma(\n",
    "    persist_directory=vector_db_path,\n",
    "    embedding_function=embeddings\n",
    ").as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# BM25 검색기 (키워드 기반 검색)\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=transformed_docs\n",
    ")\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# Ensemble Retriever 생성\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    weights=[0.7, 0.3]  # 벡터 검색에 더 높은 가중치\n",
    ")\n",
    "\n",
    "print(\"✅ Ensemble Retriever 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c2478ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAG Chain 생성 완료\n"
     ]
    }
   ],
   "source": [
    "## RAG chain 구성\n",
    "\n",
    "## RAG Chain - Ensemble Retriever를 이용한 답변 생성\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# RAG를 위한 프롬프트 템플릿 생성\n",
    "qa_prompt_template = \"\"\"당신은 별별렌터카의 친절한 고객 상담원입니다. \n",
    "아래의 참조 문서를 바탕으로 고객의 질문에 정확하고 친절하게 답변해주세요.\n",
    "\n",
    "참조 문서:\n",
    "{context}\n",
    "\n",
    "고객 질문: {question}\n",
    "\n",
    "답변 시 다음 사항을 지켜주세요:\n",
    "1. 참조 문서의 내용을 바탕으로 정확한 정보 제공\n",
    "2. 친근하고 이해하기 쉬운 언어 사용\n",
    "3. 필요한 경우 구체적인 예시나 단계별 설명 제공\n",
    "4. 한국어로 답변\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "QA_PROMPT = PromptTemplate(\n",
    "    template=qa_prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# RAG Chain 생성\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=ensemble_retriever,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": QA_PROMPT,\n",
    "        \"verbose\": True\n",
    "    },\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"✅ RAG Chain 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19385e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SKTelecom\\llm-mvp\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\SKTelecom\\AppData\\Local\\Temp\\ipykernel_26956\\1936241505.py:102: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Gradio를 이용한 대화형 별별렌터카 FAQ 챗봇 (에러 수정)\n",
    "\n",
    "import gradio as gr\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 기존 설정들 로드\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_db_path = \"./vector_db/skrc_faq\"\n",
    "\n",
    "# 벡터 검색기\n",
    "vector_retriever = Chroma(\n",
    "    persist_directory=vector_db_path,\n",
    "    embedding_function=embeddings\n",
    ").as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# BM25 검색기\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=transformed_docs\n",
    ")\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# Ensemble Retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    weights=[0.7, 0.3]\n",
    ")\n",
    "\n",
    "# LLM 모델\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0.1,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "def get_faq_answer(question):\n",
    "    \"\"\"FAQ 질문에 대한 답변을 생성하는 함수\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Ensemble Retriever로 관련 문서 검색\n",
    "        relevant_docs = ensemble_retriever.get_relevant_documents(question, k=3)\n",
    "        \n",
    "        # 컨텍스트 생성\n",
    "        context = \"\"\n",
    "        for i, doc in enumerate(relevant_docs):\n",
    "            context += f\"[문서 {i+1}]\\n\"\n",
    "            context += f\"질문: {doc.metadata['question']}\\n\"\n",
    "            context += f\"답변: {doc.metadata['answer']}\\n\"\n",
    "            context += f\"요약: {doc.metadata['summary']}\\n\\n\"\n",
    "        \n",
    "        # 수정된 RAG 프롬프트\n",
    "        prompt = f\"\"\"당신은 별별렌터카의 친절한 고객 상담원입니다.\n",
    "\n",
    "참조 문서:\n",
    "{context}\n",
    "\n",
    "고객 질문: {question}\n",
    "\n",
    "위 참조 문서를 바탕으로 정확하고 친절하게 답변해주세요.\n",
    "\n",
    "**중요한 규칙:**\n",
    "1. 명확한 근거가 없으면 \"근거없음\"으로 답변하세요\n",
    "2. 답변하기 어려운 질문은 \"잘 모르겠습니다\"라고 대답하세요\n",
    "3. 추측이나 일반적인 지식을 이용하지 마세요\n",
    "4. 참조 문서의 내용만을 바탕으로 답변하세요\n",
    "5. 답변은 한국어로 작성하고, 필요시 구체적인 예시를 포함하세요\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "        # 답변 생성\n",
    "        response = llm.invoke(prompt)\n",
    "        answer = response.content\n",
    "        \n",
    "        # 참조 문서 정보 추가\n",
    "        reference_info = \"\\n\\n📚 참조 문서:\\n\"\n",
    "        for i, doc in enumerate(relevant_docs):\n",
    "            reference_info += f\"• {doc.metadata['question']}\\n\"\n",
    "        \n",
    "        full_answer = answer + reference_info\n",
    "        \n",
    "        return full_answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"죄송합니다. 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "# Gradio 인터페이스 구성\n",
    "with gr.Blocks(title=\"별별렌터카 FAQ 챗봇\", theme=gr.themes.Soft()) as demo:\n",
    "    \n",
    "    # 헤더\n",
    "    gr.Markdown(\"# �� 별별렌터카 FAQ 챗봇\")\n",
    "    gr.Markdown(\"렌터카 이용에 궁금한 점이 있으시면 언제든 물어보세요!\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            # 챗봇 인터페이스 - 메시지 형식 수정\n",
    "            chatbot = gr.Chatbot(\n",
    "                height=500, \n",
    "                show_label=False\n",
    "            )\n",
    "            \n",
    "            # 입력 필드와 버튼을 한 줄에 배치\n",
    "            with gr.Row():\n",
    "                msg = gr.Textbox(\n",
    "                    placeholder=\"질문을 입력하세요...\",\n",
    "                    show_label=False,\n",
    "                    lines=2,\n",
    "                    scale=4\n",
    "                )\n",
    "                submit_btn = gr.Button(\"전송\", variant=\"primary\", size=\"lg\", scale=1)\n",
    "            \n",
    "            # 대화 초기화 버튼\n",
    "            clear = gr.Button(\"대화 초기화\", variant=\"secondary\")\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### 💡 예시 질문\")\n",
    "            gr.Markdown(\"\"\"\n",
    "            • 제주지점에서 이용 가능한 부가용품은 무엇인가요?\n",
    "            • 렌터카 결제는 어떻게 하나요?\n",
    "            • 유아용품을 대여할 수 있나요?\n",
    "            • 전기차 충전료는 어떻게 정산되나요?\n",
    "            • 예약을 변경하고 싶어요\n",
    "            \"\"\")\n",
    "    \n",
    "    def respond(message, chat_history):\n",
    "        if message.strip() == \"\":\n",
    "            return chat_history, \"\"\n",
    "        \n",
    "        bot_message = get_faq_answer(message)\n",
    "        \n",
    "        # 메시지 형식을 올바르게 구성\n",
    "        chat_history.append([message, bot_message])\n",
    "        return chat_history, \"\"\n",
    "    \n",
    "    # 이벤트 연결\n",
    "    submit_btn.click(respond, [msg, chatbot], [chatbot, msg])  # 전송 버튼 클릭\n",
    "    msg.submit(respond, [msg, chatbot], [chatbot, msg])        # Enter 키 입력\n",
    "    clear.click(lambda: ([], \"\"), outputs=[chatbot, msg])       # 초기화 버튼\n",
    "\n",
    "# Gradio 앱 실행\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 먼저 7860 포트로 시도\n",
    "        demo.launch(\n",
    "            server_name=\"127.0.0.1\",\n",
    "            server_port=7860,\n",
    "            share=True,\n",
    "            show_error=True\n",
    "        )\n",
    "    except OSError:\n",
    "        try:\n",
    "            # 7860이 사용 중이면 7861로 시도\n",
    "            print(\"포트 7860이 사용 중입니다. 포트 7861로 시도합니다...\")\n",
    "            demo.launch(\n",
    "                server_name=\"127.0.0.1\",\n",
    "                server_port=7861,\n",
    "                share=True,\n",
    "                show_error=True\n",
    "            )\n",
    "        except OSError:\n",
    "            # 자동으로 사용 가능한 포트 찾기\n",
    "            print(\"자동으로 사용 가능한 포트를 찾습니다...\")\n",
    "            demo.launch(\n",
    "                server_name=\"127.0.0.1\",\n",
    "                server_port=None,  # 자동 포트 할당\n",
    "                share=True,\n",
    "                show_error=True\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
