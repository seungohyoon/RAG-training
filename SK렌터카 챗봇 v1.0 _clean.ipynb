{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954d011d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## í™˜ê²½ì„¤ì •\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ee2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a604c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì„ ì–¸\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0.1,\n",
    "    top_p=0.9, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9001864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œì˜ ìˆ˜: 42\n",
      "--------------------------------------------------\n",
      "ì²˜ìŒ ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°: \n",
      " {'source': './data/skrc_faq.csv', 'row': 0}\n",
      "--------------------------------------------------\n",
      "ì²˜ìŒ ë¬¸ì„œì˜ ë‚´ìš©: \n",
      " question: ì œì£¼ì§€ì ì—ì„œ ì´ìš© ê°€ëŠ¥í•œ ë¶€ê°€ìš©í’ˆì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?\n",
      "answer: ê³ ê°ë‹˜ì˜ ì¦ê±°ìš´ ì—¬í–‰ì„ ìœ„í•´ ì œì£¼ì§€ì ë§Œì˜ ë‹¤ì–‘í•œ ë¶€ê°€ìš©í’ˆì„ ìš´ì˜í•˜ê³  ìˆì–´ìš”.\n",
      "ì°¨ëŸ‰ ì˜ˆì•½ ì‹œ ë¶€ê°€ìƒí’ˆë„ í•œ ë²ˆì— ì˜ˆì•½í•˜ê³  ê²°ì œí•˜ì‹¤ ìˆ˜ ìˆì–´ìš”. \n",
      "\n",
      "â€¢ ìœ ì•„ìš©í’ˆ : ìœ ëª¨ì°¨, ì¹´ì‹œíŠ¸\n",
      "â€¢ ì „ê¸°ì°¨ ì—¬í–‰í…œ  : ì¹´í˜KIT, ì‹œë„¤ë§ˆ KIT(êµ­ì‚° ì „ê¸°ì°¨ ì „ìš©, * ë‹ˆë¡œ ì œì™¸)\n",
      "â€¢ ì—¬í–‰í…œ(ì „ ì°¨ì¢…) :  ìì „ê±°, íŠ¸ë ˆí‚¹, í”¼í¬ë‹‰ ì„¸íŠ¸\n",
      "â€¢ í‚¤ì¦ˆ êµ¿ì¦ˆ :  ì¿¨ì‹œíŠ¸, ë¶€ìŠ¤í„°, í‚¥ë³´ë“œ, í–‡ë¹› ê°€ë¦¬ê°œ\n"
     ]
    }
   ],
   "source": [
    "## csv ë¬¸ì„œ ë¡œë“œ\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# ê¸°ë³¸ íŒŒì¼ ë¡œë“œ\n",
    "csv_loader = CSVLoader(\"./data/skrc_faq.csv\", encoding=\"utf-8\")\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(\"ë¬¸ì„œì˜ ìˆ˜:\", len(csv_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"ì²˜ìŒ ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°: \\n\", csv_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"ì²˜ìŒ ë¬¸ì„œì˜ ë‚´ìš©: \\n\", csv_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "699890cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë³€í™˜ ì‹œì‘...\n",
      "ì²˜ë¦¬ ì§„í–‰ë¥ : 10/42\n",
      "ì²˜ë¦¬ ì§„í–‰ë¥ : 20/42\n",
      "ì²˜ë¦¬ ì§„í–‰ë¥ : 30/42\n",
      "ì²˜ë¦¬ ì§„í–‰ë¥ : 40/42\n",
      "\n",
      "âœ… ë³€í™˜ ì™„ë£Œ! ì´ 42ê°œ ë¬¸ì„œ\n"
     ]
    }
   ],
   "source": [
    "## CSV ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë³€í™˜ ë° í‚¤ì›Œë“œ/ìš”ì•½ ì¶”ì¶œ\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# í‚¤ì›Œë“œì™€ ìš”ì•½ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "def extract_keyword_and_summary(text, llm):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œì™€ ìš”ì•½ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # í‚¤ì›Œë“œ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸\n",
    "    keyword_prompt = f\"\"\"\n",
    "    ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 3-5ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. \n",
    "    ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n",
    "    \n",
    "    í…ìŠ¤íŠ¸: {text}\n",
    "    \n",
    "    í‚¤ì›Œë“œ:\"\"\"\n",
    "    \n",
    "    # ìš”ì•½ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸\n",
    "    summary_prompt = f\"\"\"\n",
    "    ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.\n",
    "    \n",
    "    í…ìŠ¤íŠ¸: {text}\n",
    "    \n",
    "    ìš”ì•½:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "        keyword_response = llm.invoke(keyword_prompt)\n",
    "        keywords = keyword_response.content.strip()\n",
    "        \n",
    "        # ìš”ì•½ ì¶”ì¶œ\n",
    "        summary_response = llm.invoke(summary_prompt)\n",
    "        summary = summary_response.content.strip()\n",
    "        \n",
    "        return keywords, summary\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"í‚¤ì›Œë“œ/ìš”ì•½ ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "        return \"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨\", \"ìš”ì•½ ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "\n",
    "# CSV ë¬¸ì„œë¥¼ ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "def transform_csv_docs_metadata(csv_docs, llm):\n",
    "    \"\"\"CSV ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    \n",
    "    transformed_docs = []\n",
    "    \n",
    "    for i, doc in enumerate(csv_docs):\n",
    "        try:\n",
    "            # ê¸°ì¡´ ë‚´ìš©ì—ì„œ ì§ˆë¬¸ê³¼ ë‹µë³€ ì¶”ì¶œ\n",
    "            content = doc.page_content\n",
    "            \n",
    "            # CSV í˜•ì‹ì— ë”°ë¼ ì§ˆë¬¸ê³¼ ë‹µë³€ íŒŒì‹±\n",
    "            if 'question:' in content and 'answer:' in content:\n",
    "                # ì§ˆë¬¸ê³¼ ë‹µë³€ ë¶„ë¦¬\n",
    "                parts = content.split('answer:')\n",
    "                question_part = parts[0].replace('question:', '').strip()\n",
    "                answer_part = parts[1].strip()\n",
    "                \n",
    "                question = question_part\n",
    "                answer = answer_part\n",
    "            else:\n",
    "                # ë‹¤ë¥¸ í˜•ì‹ì¸ ê²½ìš° ì „ì²´ ë‚´ìš©ì„ ì‚¬ìš©\n",
    "                question = content\n",
    "                answer = content\n",
    "            \n",
    "            # í‚¤ì›Œë“œì™€ ìš”ì•½ ì¶”ì¶œ\n",
    "            full_text = f\"{question}\\n\\n{answer}\"\n",
    "            keywords, summary = extract_keyword_and_summary(full_text, llm)\n",
    "            \n",
    "            # ìƒˆë¡œìš´ Document ê°ì²´ ìƒì„±\n",
    "            new_doc = Document(\n",
    "                page_content=doc.page_content,  # ê¸°ì¡´ ë‚´ìš© ìœ ì§€\n",
    "                metadata={\n",
    "                    'question_id': i + 1,  # 1ë¶€í„° ì‹œì‘í•˜ëŠ” ID\n",
    "                    'question': question,\n",
    "                    'answer': answer,\n",
    "                    'keyword': keywords,\n",
    "                    'summary': summary\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            transformed_docs.append(new_doc)\n",
    "            \n",
    "            # ì§„í–‰ìƒí™© ì¶œë ¥\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"ì²˜ë¦¬ ì§„í–‰ë¥ : {i + 1}/{len(csv_docs)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ë¬¸ì„œ {i+1} ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "            # ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±\n",
    "            new_doc = Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\n",
    "                    'question_id': i + 1,\n",
    "                    'question': 'ì§ˆë¬¸ ì¶”ì¶œ ì‹¤íŒ¨',\n",
    "                    'answer': 'ë‹µë³€ ì¶”ì¶œ ì‹¤íŒ¨',\n",
    "                    'keyword': 'í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨',\n",
    "                    'summary': 'ìš”ì•½ ì¶”ì¶œ ì‹¤íŒ¨'\n",
    "                }\n",
    "            )\n",
    "            transformed_docs.append(new_doc)\n",
    "    \n",
    "    return transformed_docs\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„° ë³€í™˜ ì‹¤í–‰\n",
    "print(\"CSV ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë³€í™˜ ì‹œì‘...\")\n",
    "transformed_docs = transform_csv_docs_metadata(csv_docs, llm)\n",
    "\n",
    "print(f\"\\nâœ… ë³€í™˜ ì™„ë£Œ! ì´ {len(transformed_docs)}ê°œ ë¬¸ì„œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899df378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë²¡í„°DB ì €ì¥ ì™„ë£Œ: 42ê°œ ë¬¸ì„œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SKTelecom\\AppData\\Local\\Temp\\ipykernel_26956\\2513845666.py:25: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "## ë²¡í„°DBì— transformed_docs ì €ì¥\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# ë²¡í„°DB ì €ì¥ ê²½ë¡œ\n",
    "vector_db_path = \"./vector_db/skrc_faq\"\n",
    "\n",
    "# ê¸°ì¡´ ë²¡í„°DB ì‚­ì œ\n",
    "if os.path.exists(vector_db_path):\n",
    "    import shutil\n",
    "    shutil.rmtree(vector_db_path)\n",
    "\n",
    "# ë²¡í„°DB ìƒì„± ë° ì €ì¥\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=transformed_docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=vector_db_path\n",
    ")\n",
    "\n",
    "vectorstore.persist()\n",
    "print(f\"âœ… ë²¡í„°DB ì €ì¥ ì™„ë£Œ: {len(transformed_docs)}ê°œ ë¬¸ì„œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf0ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ensemble Retriever ìƒì„± ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SKTelecom\\AppData\\Local\\Temp\\ipykernel_26956\\1136353814.py:14: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_retriever = Chroma(\n"
     ]
    }
   ],
   "source": [
    "## Ensemble Retrieverë¥¼ ì´ìš©í•œ ê²€ìƒ‰\n",
    "\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ê³¼ ë²¡í„°DB ë¡œë“œ\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_db_path = \"./vector_db/skrc_faq\"\n",
    "\n",
    "# ë²¡í„° ê²€ìƒ‰ê¸° (Vector Retriever)\n",
    "vector_retriever = Chroma(\n",
    "    persist_directory=vector_db_path,\n",
    "    embedding_function=embeddings\n",
    ").as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# BM25 ê²€ìƒ‰ê¸° (í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰)\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=transformed_docs\n",
    ")\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# Ensemble Retriever ìƒì„±\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    weights=[0.7, 0.3]  # ë²¡í„° ê²€ìƒ‰ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜\n",
    ")\n",
    "\n",
    "print(\"âœ… Ensemble Retriever ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c2478ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG Chain ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "## RAG chain êµ¬ì„±\n",
    "\n",
    "## RAG Chain - Ensemble Retrieverë¥¼ ì´ìš©í•œ ë‹µë³€ ìƒì„±\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# RAGë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "qa_prompt_template = \"\"\"ë‹¹ì‹ ì€ ë³„ë³„ë Œí„°ì¹´ì˜ ì¹œì ˆí•œ ê³ ê° ìƒë‹´ì›ì…ë‹ˆë‹¤. \n",
    "ì•„ë˜ì˜ ì°¸ì¡° ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì°¸ì¡° ë¬¸ì„œ:\n",
    "{context}\n",
    "\n",
    "ê³ ê° ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ì§€ì¼œì£¼ì„¸ìš”:\n",
    "1. ì°¸ì¡° ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ ì œê³µ\n",
    "2. ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ ì‚¬ìš©\n",
    "3. í•„ìš”í•œ ê²½ìš° êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ë‹¨ê³„ë³„ ì„¤ëª… ì œê³µ\n",
    "4. í•œêµ­ì–´ë¡œ ë‹µë³€\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "QA_PROMPT = PromptTemplate(\n",
    "    template=qa_prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# RAG Chain ìƒì„±\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=ensemble_retriever,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": QA_PROMPT,\n",
    "        \"verbose\": True\n",
    "    },\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG Chain ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19385e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SKTelecom\\llm-mvp\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\SKTelecom\\AppData\\Local\\Temp\\ipykernel_26956\\1936241505.py:102: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Gradioë¥¼ ì´ìš©í•œ ëŒ€í™”í˜• ë³„ë³„ë Œí„°ì¹´ FAQ ì±—ë´‡ (ì—ëŸ¬ ìˆ˜ì •)\n",
    "\n",
    "import gradio as gr\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# ê¸°ì¡´ ì„¤ì •ë“¤ ë¡œë“œ\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_db_path = \"./vector_db/skrc_faq\"\n",
    "\n",
    "# ë²¡í„° ê²€ìƒ‰ê¸°\n",
    "vector_retriever = Chroma(\n",
    "    persist_directory=vector_db_path,\n",
    "    embedding_function=embeddings\n",
    ").as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# BM25 ê²€ìƒ‰ê¸°\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=transformed_docs\n",
    ")\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# Ensemble Retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    weights=[0.7, 0.3]\n",
    ")\n",
    "\n",
    "# LLM ëª¨ë¸\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0.1,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "def get_faq_answer(question):\n",
    "    \"\"\"FAQ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Ensemble Retrieverë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "        relevant_docs = ensemble_retriever.get_relevant_documents(question, k=3)\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±\n",
    "        context = \"\"\n",
    "        for i, doc in enumerate(relevant_docs):\n",
    "            context += f\"[ë¬¸ì„œ {i+1}]\\n\"\n",
    "            context += f\"ì§ˆë¬¸: {doc.metadata['question']}\\n\"\n",
    "            context += f\"ë‹µë³€: {doc.metadata['answer']}\\n\"\n",
    "            context += f\"ìš”ì•½: {doc.metadata['summary']}\\n\\n\"\n",
    "        \n",
    "        # ìˆ˜ì •ëœ RAG í”„ë¡¬í”„íŠ¸\n",
    "        prompt = f\"\"\"ë‹¹ì‹ ì€ ë³„ë³„ë Œí„°ì¹´ì˜ ì¹œì ˆí•œ ê³ ê° ìƒë‹´ì›ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì°¸ì¡° ë¬¸ì„œ:\n",
    "{context}\n",
    "\n",
    "ê³ ê° ì§ˆë¬¸: {question}\n",
    "\n",
    "ìœ„ ì°¸ì¡° ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "**ì¤‘ìš”í•œ ê·œì¹™:**\n",
    "1. ëª…í™•í•œ ê·¼ê±°ê°€ ì—†ìœ¼ë©´ \"ê·¼ê±°ì—†ìŒ\"ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”\n",
    "2. ë‹µë³€í•˜ê¸° ì–´ë ¤ìš´ ì§ˆë¬¸ì€ \"ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤\"ë¼ê³  ëŒ€ë‹µí•˜ì„¸ìš”\n",
    "3. ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ì ì¸ ì§€ì‹ì„ ì´ìš©í•˜ì§€ ë§ˆì„¸ìš”\n",
    "4. ì°¸ì¡° ë¬¸ì„œì˜ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”\n",
    "5. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , í•„ìš”ì‹œ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "\n",
    "        # ë‹µë³€ ìƒì„±\n",
    "        response = llm.invoke(prompt)\n",
    "        answer = response.content\n",
    "        \n",
    "        # ì°¸ì¡° ë¬¸ì„œ ì •ë³´ ì¶”ê°€\n",
    "        reference_info = \"\\n\\nğŸ“š ì°¸ì¡° ë¬¸ì„œ:\\n\"\n",
    "        for i, doc in enumerate(relevant_docs):\n",
    "            reference_info += f\"â€¢ {doc.metadata['question']}\\n\"\n",
    "        \n",
    "        full_answer = answer + reference_info\n",
    "        \n",
    "        return full_answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±\n",
    "with gr.Blocks(title=\"ë³„ë³„ë Œí„°ì¹´ FAQ ì±—ë´‡\", theme=gr.themes.Soft()) as demo:\n",
    "    \n",
    "    # í—¤ë”\n",
    "    gr.Markdown(\"# ï¿½ï¿½ ë³„ë³„ë Œí„°ì¹´ FAQ ì±—ë´‡\")\n",
    "    gr.Markdown(\"ë Œí„°ì¹´ ì´ìš©ì— ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            # ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ - ë©”ì‹œì§€ í˜•ì‹ ìˆ˜ì •\n",
    "            chatbot = gr.Chatbot(\n",
    "                height=500, \n",
    "                show_label=False\n",
    "            )\n",
    "            \n",
    "            # ì…ë ¥ í•„ë“œì™€ ë²„íŠ¼ì„ í•œ ì¤„ì— ë°°ì¹˜\n",
    "            with gr.Row():\n",
    "                msg = gr.Textbox(\n",
    "                    placeholder=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...\",\n",
    "                    show_label=False,\n",
    "                    lines=2,\n",
    "                    scale=4\n",
    "                )\n",
    "                submit_btn = gr.Button(\"ì „ì†¡\", variant=\"primary\", size=\"lg\", scale=1)\n",
    "            \n",
    "            # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼\n",
    "            clear = gr.Button(\"ëŒ€í™” ì´ˆê¸°í™”\", variant=\"secondary\")\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸\")\n",
    "            gr.Markdown(\"\"\"\n",
    "            â€¢ ì œì£¼ì§€ì ì—ì„œ ì´ìš© ê°€ëŠ¥í•œ ë¶€ê°€ìš©í’ˆì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
    "            â€¢ ë Œí„°ì¹´ ê²°ì œëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\n",
    "            â€¢ ìœ ì•„ìš©í’ˆì„ ëŒ€ì—¬í•  ìˆ˜ ìˆë‚˜ìš”?\n",
    "            â€¢ ì „ê¸°ì°¨ ì¶©ì „ë£ŒëŠ” ì–´ë–»ê²Œ ì •ì‚°ë˜ë‚˜ìš”?\n",
    "            â€¢ ì˜ˆì•½ì„ ë³€ê²½í•˜ê³  ì‹¶ì–´ìš”\n",
    "            \"\"\")\n",
    "    \n",
    "    def respond(message, chat_history):\n",
    "        if message.strip() == \"\":\n",
    "            return chat_history, \"\"\n",
    "        \n",
    "        bot_message = get_faq_answer(message)\n",
    "        \n",
    "        # ë©”ì‹œì§€ í˜•ì‹ì„ ì˜¬ë°”ë¥´ê²Œ êµ¬ì„±\n",
    "        chat_history.append([message, bot_message])\n",
    "        return chat_history, \"\"\n",
    "    \n",
    "    # ì´ë²¤íŠ¸ ì—°ê²°\n",
    "    submit_btn.click(respond, [msg, chatbot], [chatbot, msg])  # ì „ì†¡ ë²„íŠ¼ í´ë¦­\n",
    "    msg.submit(respond, [msg, chatbot], [chatbot, msg])        # Enter í‚¤ ì…ë ¥\n",
    "    clear.click(lambda: ([], \"\"), outputs=[chatbot, msg])       # ì´ˆê¸°í™” ë²„íŠ¼\n",
    "\n",
    "# Gradio ì•± ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # ë¨¼ì € 7860 í¬íŠ¸ë¡œ ì‹œë„\n",
    "        demo.launch(\n",
    "            server_name=\"127.0.0.1\",\n",
    "            server_port=7860,\n",
    "            share=True,\n",
    "            show_error=True\n",
    "        )\n",
    "    except OSError:\n",
    "        try:\n",
    "            # 7860ì´ ì‚¬ìš© ì¤‘ì´ë©´ 7861ë¡œ ì‹œë„\n",
    "            print(\"í¬íŠ¸ 7860ì´ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. í¬íŠ¸ 7861ë¡œ ì‹œë„í•©ë‹ˆë‹¤...\")\n",
    "            demo.launch(\n",
    "                server_name=\"127.0.0.1\",\n",
    "                server_port=7861,\n",
    "                share=True,\n",
    "                show_error=True\n",
    "            )\n",
    "        except OSError:\n",
    "            # ìë™ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸ ì°¾ê¸°\n",
    "            print(\"ìë™ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤...\")\n",
    "            demo.launch(\n",
    "                server_name=\"127.0.0.1\",\n",
    "                server_port=None,  # ìë™ í¬íŠ¸ í• ë‹¹\n",
    "                share=True,\n",
    "                show_error=True\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
